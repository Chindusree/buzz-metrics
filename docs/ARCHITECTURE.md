# BUzz Metrics â€” System Architecture

**Version:** 4.4 (live as of 2026-02-05)
**Status:** Production (newsday scraping complete, workflows disabled)

---

## System Overview

BUzz Metrics is an automated journalism quality measurement system consisting of:
- **Backend:** Python scrapers + LLM-based analysis
- **Frontend:** Static HTML/JS dashboard (GitHub Pages)
- **Data:** 85 JSON files (312 articles from January 2026)
- **Automation:** GitHub Actions workflows (now disabled)

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BUZZ METRICS                             â”‚
â”‚                    (Journalism Analytics)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT LAYER
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BUzz Newsroom (WordPress)                                   â”‚
â”‚  â””â”€ 312 articles (Jan 2026)                                  â”‚
â”‚     â”œâ”€ News (350w target)                                    â”‚
â”‚     â”œâ”€ Features (800w target)                                â”‚
â”‚     â””â”€ Shorthand embeds (longform multimedia stories)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPING LAYER (Python + BeautifulSoup)                     â”‚
â”‚  â”œâ”€ scrape.py (3,453 lines) â† Main scraper                   â”‚
â”‚  â”‚   â”œâ”€ WordPress HTML extraction (BeautifulSoup)            â”‚
â”‚  â”‚   â”œâ”€ Shorthand iframe detection                           â”‚
â”‚  â”‚   â””â”€ Shorthand JSON API fallback                          â”‚
â”‚  â”œâ”€ verify.py (209 lines) â† Data validation                  â”‚
â”‚  â””â”€ compare.py (376 lines) â† Reconciliation                  â”‚
â”‚                                                               â”‚
â”‚  Output: data/metrics_verified.json                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCORING LAYER (Python + Groq LLM)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ SEI Pipeline (Source Equity Index)                      â”‚â”‚
â”‚  â”‚ â”œâ”€ sei_production.py (18K)                              â”‚â”‚
â”‚  â”‚ â”œâ”€ sei_prompt_template.md                               â”‚â”‚
â”‚  â”‚ â””â”€ Output: data/metrics_sei.json + docs/metrics_sei.jsonâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ ORI Pipeline (Original Reporting Index)                 â”‚â”‚
â”‚  â”‚ â”œâ”€ ssi_score.py (23K)  â† "ssi" = legacy name            â”‚â”‚
â”‚  â”‚ â”œâ”€ ssi_prompt_v2.1.md / ngi_prompt_v2.2.md              â”‚â”‚
â”‚  â”‚ â””â”€ Output: data/metrics_ssi.json + docs/metrics_ssi.jsonâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ BNS Pipeline (Breaking News Score)                      â”‚â”‚
â”‚  â”‚ â””â”€ Integrated in scrape.py                              â”‚â”‚
â”‚  â”‚    Output: data/metrics_bns.json + docs/metrics_bns.jsonâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PUBLICATION LAYER (GitHub Pages)                            â”‚
â”‚  â”œâ”€ docs/index.html (101K) â† Live dashboard                 â”‚
â”‚  â”œâ”€ docs/staff-test.html (101K) â† Dev version               â”‚
â”‚  â””â”€ docs/metrics_*.json â† Deployed data                     â”‚
â”‚                                                               â”‚
â”‚  Merges SEI + ORI + BNS on client-side by article URL       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER LAYER                                                   â”‚
â”‚  â””â”€ https://chindusree.github.io/buzz-metrics/              â”‚
â”‚     â”œâ”€ Filter by date/category                              â”‚
â”‚     â”œâ”€ View 3 index cards (SEI, ORI, BNS)                   â”‚
â”‚     â””â”€ Explore article-level scores                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AUTOMATION (Disabled post-newsday)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions Workflows                                    â”‚
â”‚  â”œâ”€ scrape.yml.disabled (was: hourly 8am-5pm Mon-Fri)       â”‚
â”‚  â”œâ”€ sei_daily.yml.disabled (was: 1pm + 4pm Mon-Fri)         â”‚
â”‚  â””â”€ ssi_daily.yml.disabled (was: 5pm Mon-Fri)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Structure

```
buzz-metrics/
â”œâ”€â”€ README.md                          # Public documentation
â”œâ”€â”€ CLEANUP_AUDIT.md                   # Maintenance plan
â”œâ”€â”€ .env                               # API keys (gitignored)
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ .github/workflows/                 # Automation (disabled)
â”‚   â”œâ”€â”€ scrape.yml.disabled
â”‚   â”œâ”€â”€ sei_daily.yml.disabled
â”‚   â””â”€â”€ ssi_daily.yml.disabled
â”‚
â”œâ”€â”€ data/                              # Production data (85 files)
â”‚   â”œâ”€â”€ metrics_sei.json              # SEI scores + article metadata
â”‚   â”œâ”€â”€ metrics_ssi.json              # ORI scores (legacy name)
â”‚   â”œâ”€â”€ metrics_bns.json              # Breaking news scores
â”‚   â”œâ”€â”€ metrics_verified.json         # Scraper output
â”‚   â”œâ”€â”€ imr_*.json                    # Inter-Model Reliability validation
â”‚   â””â”€â”€ [82 other JSON files]         # Historical/backup data
â”‚
â”œâ”€â”€ docs/                              # GitHub Pages deployment
â”‚   â”œâ”€â”€ index.html                     # ðŸ”´ LIVE DASHBOARD
â”‚   â”œâ”€â”€ staff-test.html                # Development version
â”‚   â”œâ”€â”€ metrics_sei.json              # Deployed SEI data
â”‚   â”œâ”€â”€ metrics_ssi.json              # Deployed ORI data
â”‚   â”œâ”€â”€ metrics_bns.json              # Deployed BNS data
â”‚   â”œâ”€â”€ index-backup-20260204.html    # Pre-deployment backup
â”‚   â”œâ”€â”€ [16 archived HTML files]       # Old development versions
â”‚   â”‚
â”‚   â””â”€â”€ decisions/                     # Architecture Decision Records
â”‚       â”œâ”€â”€ 001-data-architecture.md   # Why separate JSON files
â”‚       â””â”€â”€ 002-ssi-ori-naming.md      # Why keep SSI filenames
â”‚
â”œâ”€â”€ scraper/                           # Backend processing
â”‚   â”œâ”€â”€ requirements.txt               # Python dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ [PRODUCTION SCRIPTS - 6 files]
â”‚   â”œâ”€â”€ scrape.py                      # Main scraper (132K)
â”‚   â”œâ”€â”€ verify.py                      # Validation pipeline
â”‚   â”œâ”€â”€ compare.py                     # Data reconciliation
â”‚   â”œâ”€â”€ reconcile.py                   # Comparison logic
â”‚   â”œâ”€â”€ sei_production.py              # SEI scoring
â”‚   â””â”€â”€ ssi_score.py                   # ORI scoring (legacy name)
â”‚   â”‚
â”‚   â”œâ”€â”€ [LLM PROMPTS - 3 files]
â”‚   â”œâ”€â”€ sei_prompt_template.md         # SEI scoring instructions
â”‚   â”œâ”€â”€ ssi_prompt_v2.1.md             # ORI v2.1 prompt
â”‚   â””â”€â”€ ngi_prompt_v2.2.md             # ORI v2.2 prompt (NGI = old name)
â”‚   â”‚
â”‚   â”œâ”€â”€ [DOCUMENTATION - 9 files]
â”‚   â”œâ”€â”€ GROQ_SETUP.md
â”‚   â”œâ”€â”€ BUG_RESOLUTION.md
â”‚   â”œâ”€â”€ FIXES_VERIFICATION.md
â”‚   â”œâ”€â”€ ANNE_MARIE_DEBUG_REPORT.md
â”‚   â”œâ”€â”€ SHORTHAND_EXTRACTION_CLARIFICATION.md
â”‚   â””â”€â”€ COMPARISON_BEFORE_AFTER.md
â”‚   â”‚
â”‚   â””â”€â”€ [SUPPORT SCRIPTS - 47 files]
â”‚       â”œâ”€â”€ debug_*.py (15 files)      # Debugging scripts
â”‚       â”œâ”€â”€ test_*.py (21 files)       # Test/validation scripts
â”‚       â””â”€â”€ [11 migration/audit scripts]
â”‚
â””â”€â”€ analysis/                          # Investigation reports
    â””â”€â”€ [10 markdown reports]
```

---

## Component Inventory

### Production Components (101 items)
| Category | Count | Purpose |
|----------|-------|---------|
| **Python scripts** | 6 | Scraping + scoring pipelines |
| **LLM prompts** | 3 | SEI + ORI scoring instructions |
| **Dashboards** | 2 | Live + development HTML |
| **Data files** | 85 | Article scores + metadata |
| **Workflows** | 3 | Automation (disabled) |
| **ADRs** | 2 | Architecture decisions |

### Support Components (115 items)
| Category | Count | Purpose |
|----------|-------|---------|
| **Debug scripts** | 36 | Development troubleshooting |
| **Migration scripts** | 11 | One-time data operations |
| **Archive HTML** | 17 | Old dashboard versions |
| **Documentation** | 9 | Technical notes |
| **Analysis reports** | 10 | Investigation findings |
| **Config files** | 5 | Git, Python, env |
| **Root docs** | 6 | README, cleanup, handover |
| **Backup data** | ~21 | Historical JSON files |

### Total Project Files: **216 files**
(Excluding venv/ and .git/)

---

## Data Flow

### 1. Article Collection
```
WordPress API â†’ scrape.py â†’ metrics_verified.json
- Extracts: headline, text, date, URL, category, word_count
- Handles: Shorthand embeds, iframe content
- Validates: Text extraction, duplicate detection
```

### 2. SEI Scoring (Source Equity Index)
```
metrics_verified.json â†’ sei_production.py â†’ metrics_sei.json
- LLM: Groq (Llama 3.1 70B)
- Prompt: sei_prompt_template.md
- Components: Inclusion, Agency, Perspectives
- Output: 266 scored articles (46 exempt)
```

### 3. ORI Scoring (Original Reporting Index)
```
metrics_verified.json â†’ ssi_score.py â†’ metrics_ssi.json
- LLM: Groq (Llama 3.1 70B)
- Prompt: ngi_prompt_v2.2.md (latest)
- Components: WE, SD, AR, CD, OI
- Output: 295 scored articles (17 exempt)
```

### 4. BNS Scoring (Breaking News Score)
```
Integrated in scrape.py â†’ metrics_bns.json
- Compares BUzz publish time vs external media
- Output: 17 breaking news articles
```

### 5. Frontend Merge
```javascript
// Client-side merge in index.html
const merged = sei_articles.map(article => ({
  ...article,
  ssi_score: ssi_data.find(s => s.url === article.url)?.ssi_score,
  bns_score: bns_data.find(b => b.url === article.url)?.bns_score
}))
```

---

## Key Design Decisions

### 1. Separate JSON Files (ADR-001)
**Why:** Race condition prevention during concurrent workflow runs
- `metrics_sei.json` â€” Article metadata + SEI
- `metrics_ssi.json` â€” ORI scores only
- `metrics_bns.json` â€” BNS scores only

### 2. Keep SSI Filenames (ADR-002)
**Why:** Stability over consistency
- Backend: `ssi_score.py`, `metrics_ssi.json` (unchanged)
- Frontend: "ORI" everywhere visible to users
- No user impact, preserves git history

### 3. GitHub Pages Deployment
**Why:** Zero hosting cost, automatic SSL, version control
- Every push triggers rebuild (1-5 min)
- Data files live in `docs/` for direct access

### 4. Client-Side Data Merge
**Why:** Simplicity + independence
- No build step required
- Each index can be updated independently
- ~10 lines of JavaScript, <50ms latency

---

## Technology Stack

### Backend
- **Python 3.9+** â€” Scraping + scoring
- **BeautifulSoup4** â€” HTML parsing
- **spaCy** â€” Named entity recognition
- **Groq API** â€” LLM inference (Llama 3.1 70B)
- **requests** â€” HTTP client

### Frontend
- **Vanilla JavaScript** â€” No framework
- **HTML5 + CSS3** â€” Responsive design
- **GitHub Pages** â€” Static hosting

### Automation
- **GitHub Actions** â€” Scheduled workflows (now disabled)
- **Ubuntu 20.04** â€” Runner environment

### Data
- **JSON** â€” All data storage
- **85 files** â€” ~50MB total

---

## Validation & Quality

### Inter-Model Reliability (IMR)
- **Method:** 10% stratified sample, two independent LLMs
- **SEI:** 84.5% agreement (N=31)
- **ORI:** 85.0% agreement (N=30)
- **Interpretation:** Validates extraction consistency

### Exemptions
- **SEI:** 46 exempt (match reports, court registers, breaking, live blogs)
- **ORI:** 17 exempt (video/audio only, non-text content)

---

## Deployment Timeline

| Version | Date | Milestone |
|---------|------|-----------|
| v7.37.1-stable | 20 Jan | Pre-ORI rename |
| v8.2 | 22 Jan | Mobile responsiveness |
| v4.3-pre-live | 4 Feb | Staff dashboard complete |
| v4.4-live | 5 Feb | ðŸ”´ **PRODUCTION DEPLOYMENT** |
| v4.5-pre-cleanup | 5 Feb | Checkpoint before cleanup |
| v4.5-cleanup | 5 Feb | âœ… **Archived 75 development files** |

---

## Maintenance Status

**As of 2026-02-05:**
- âœ… Newsday scraping complete (312 articles)
- âœ… All workflows disabled
- âœ… Dashboard live at chindusree.github.io/buzz-metrics
- âœ… Repository cleanup complete (75 files archived)
- â¸ï¸ No further automated updates planned
- ðŸ“¦ Archive accessible via `archive/` folders and git tags

---

## For Developers

### Quick Start
```bash
git clone https://github.com/Chindusree/buzz-metrics.git
cd buzz-metrics/scraper
pip install -r requirements.txt
```

### Run Scoring Locally
```bash
# Requires GROQ_API_KEY in .env
python3 sei_production.py    # SEI scoring
python3 ssi_score.py          # ORI scoring
```

### View Dashboard Locally
```bash
cd docs
python3 -m http.server 8000
# Open http://localhost:8000
```

### Architecture Decisions
See `docs/decisions/*.md` for rationale behind key design choices.

---

**Generated:** 2026-02-05
**Maintained by:** Chindu Sreedharan (csreedharan@bournemouth.ac.uk)
